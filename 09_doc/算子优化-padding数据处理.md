åœ¨è®¡ç®— **Softmax**ã€**Loss**ï¼ˆå¦‚ Cross Entropyï¼‰ç­‰æ¶‰åŠ **å½’ä¸€åŒ–** æˆ– **å‡å€¼è®¡ç®—** çš„ç®—å­æ—¶ï¼Œ**Padding æ•°æ®** å¯èƒ½ä¼šå½±å“ç»“æœï¼Œå¯¼è‡´ä¸å¿…è¦çš„åå·®ã€‚é’ˆå¯¹è¿™ä¸ªé—®é¢˜ï¼Œå¯ä»¥é‡‡å–ä»¥ä¸‹ä¼˜åŒ–æ–¹æ¡ˆï¼š  

---

## **1. è¯†åˆ« Padding æ•°æ®å¹¶å±è”½**
- è®¡ç®—æ—¶åº”**å¿½ç•¥ Padding æ•°æ®**ï¼Œé¿å…å…¶å¯¹å½’ä¸€åŒ–ã€å‡å€¼è®¡ç®—ç­‰æ“ä½œäº§ç”Ÿå½±å“ã€‚
- æ–¹å¼ï¼š
  - ä½¿ç”¨ Maskï¼ˆæ©ç ï¼‰æ ‡è¯† Padding æ•°æ®ï¼Œåœ¨è®¡ç®— Softmaxã€Loss æ—¶æ’é™¤ã€‚
  - å½’ä¸€åŒ–æ—¶ä»…åŸºäº **æœ‰æ•ˆæ•°æ®** è¿›è¡Œè®¡ç®—ã€‚

---

## **2. å¤„ç† Softmax è®¡ç®—ä¸­çš„ Padding**
### **é—®é¢˜**
Softmax è®¡ç®—å…¬å¼ï¼š
\[
\text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}
\]
- å¦‚æœ `x_i` å¯¹åº”çš„æ˜¯ Padding æ•°æ®ï¼Œä»ç„¶ä¼šå‚ä¸ `sum(exp(x))` è®¡ç®—ï¼Œå½±å“å½’ä¸€åŒ–ç»“æœã€‚

### **è§£å†³æ–¹æ¡ˆ**
**æ–¹æ³• 1**ï¼šå¯¹ Padding ä½ç½®çš„ `x` èµ‹äºˆæå°å€¼ï¼ˆå¦‚ `-inf`ï¼‰ï¼Œä½¿ `exp(-inf) â‰ˆ 0`ï¼Œè¿™æ ·ä¸ä¼šå½±å“æ€»å’Œï¼š
```python
import numpy as np

def masked_softmax(x, mask):
    x = np.where(mask, x, -np.inf)  # å¯¹ Padding ä½ç½®è®¾ä¸º -inf
    exp_x = np.exp(x - np.max(x))  # é˜²æ­¢æº¢å‡º
    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)

x = np.array([[1.0, 2.0, 3.0, 0.0], [4.0, 5.0, -1.0, 0.0]])
mask = np.array([[1, 1, 1, 0], [1, 1, 1, 0]])  # 1 ä»£è¡¨æœ‰æ•ˆæ•°æ®ï¼Œ0 ä»£è¡¨ Padding
softmax_result = masked_softmax(x, mask)
```
**æ–¹æ³• 2**ï¼šåœ¨è®¡ç®— `sum(exp(x))` æ—¶ä»…ç´¯åŠ  **æœ‰æ•ˆæ•°æ®**ï¼š
```python
def masked_softmax_v2(x, mask):
    exp_x = np.exp(x - np.max(x)) * mask  # åªè®¡ç®—æœ‰æ•ˆéƒ¨åˆ†
    return exp_x / (np.sum(exp_x, axis=-1, keepdims=True) + 1e-9)  # é¿å…é™¤é›¶

softmax_result = masked_softmax_v2(x, mask)
```
> **æ€»ç»“**ï¼š
> - `-inf` æ–¹å¼é€‚ç”¨äº batch å¤„ç†ï¼Œæ”¯æŒå¹¿æ’­è®¡ç®—ã€‚
> - ç›´æ¥ `mask` æ–¹å¼é€‚ç”¨äºçŸ©é˜µè®¡ç®—ï¼Œé¿å…æ— æ•ˆæ•°æ®å¹²æ‰°å½’ä¸€åŒ–ã€‚

---

## **3. å¤„ç† Loss è®¡ç®—ä¸­çš„ Padding**
### **é—®é¢˜**
ä»¥ **äº¤å‰ç†µï¼ˆCross Entropy Lossï¼‰** ä¸ºä¾‹ï¼š
\[
L = -\frac{1}{N} \sum_{i=1}^{N} y_i \log(\hat{y}_i)
\]
- å¦‚æœ `y_i` æ˜¯ Padding æ•°æ®ï¼Œä»ä¼šå½±å“ Loss å‡å€¼è®¡ç®—ã€‚

### **è§£å†³æ–¹æ¡ˆ**
- **æ–¹æ³• 1**ï¼šä»…å¯¹ **æœ‰æ•ˆæ•°æ®æ±‚å‡å€¼**ï¼š
```python
def masked_cross_entropy(pred, target, mask):
    loss = -target * np.log(pred + 1e-9)  # é¿å… log(0)
    loss = loss * mask  # åªä¿ç•™æœ‰æ•ˆæ•°æ®
    return np.sum(loss) / (np.sum(mask) + 1e-9)  # ä»…ç”¨æœ‰æ•ˆæ•°æ®æ•°ç›®å½’ä¸€åŒ–
```
- **æ–¹æ³• 2**ï¼šå¿½ç•¥ Padding æ•°æ®ï¼š
  - **Pytorch ç‰ˆæœ¬**ï¼š
  ```python
  import torch.nn.functional as F

  def masked_loss(pred, target, mask):
      loss = F.cross_entropy(pred, target, reduction='none')
      loss = loss * mask  # å±è”½ Padding ä½ç½®
      return loss.sum() / (mask.sum() + 1e-9)
  ```
  - **TensorFlow ç‰ˆæœ¬**ï¼š
  ```python
  import tensorflow as tf

  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none')
  loss = loss_fn(y_true, y_pred) * mask
  loss = tf.reduce_sum(loss) / (tf.reduce_sum(mask) + 1e-9)
  ```

> **æ€»ç»“**ï¼š
> - è®¡ç®— Loss æ—¶ï¼Œåº”é¿å… Padding æ•°æ®å¯¹å‡å€¼è®¡ç®—çš„å½±å“ã€‚
> - å½’ä¸€åŒ–æ—¶é™¤ä»¥ **æœ‰æ•ˆæ•°æ®æ•°ç›®**ï¼Œè€Œä¸æ˜¯æ•´ä¸ª batch å¤§å°ã€‚

---

## **4. é¢å¤–ä¼˜åŒ–**
### **(1) é«˜æ•ˆ SIMD å¤„ç†**
- åœ¨ Kernel è®¡ç®—æ—¶ï¼š
  - é‡‡ç”¨ **Mask å‘é‡åŒ–** è®¡ç®—ï¼Œæé«˜å¹¶è¡Œæ•ˆç‡ã€‚
  - ä»…å¯¹ **æœ‰æ•ˆæ•°æ®è¿›è¡Œè®¡ç®—**ï¼Œå‡å°‘æ— æ•ˆè®¡ç®—ã€‚

```cpp
#include <immintrin.h>  // AVX æŒ‡ä»¤
void masked_softmax_avx(float* x, float* mask, int size) {
    __m256 v_mask, v_x, v_exp, v_sum;
    v_sum = _mm256_setzero_ps();

    for (int i = 0; i < size; i += 8) {
        v_mask = _mm256_load_ps(mask + i);
        v_x = _mm256_load_ps(x + i);
        v_exp = _mm256_mul_ps(_mm256_exp_ps(v_x), v_mask);
        v_sum = _mm256_add_ps(v_sum, v_exp);
    }
}
```
### **(2) ä½ç²¾åº¦è®¡ç®—åŠ é€Ÿ**
- Softmax çš„ **å½’ä¸€åŒ–éƒ¨åˆ†** å¯¹ç²¾åº¦è¦æ±‚ä¸é«˜ï¼Œå¯ä»¥ä½¿ç”¨ **FP16ï¼ˆfloat16ï¼‰** è®¡ç®—ï¼Œæé«˜ååé‡ï¼š
  - **CUDA è®¡ç®—æ—¶** ä½¿ç”¨ `__half2` è¿›è¡Œå¹¶è¡Œè®¡ç®—ã€‚

---

## **5. æ€»ç»“**
| **é—®é¢˜** | **ä¼˜åŒ–æ–¹æ³•** |
|---------|------------|
| **Softmax å— Padding å½±å“** | ç”¨ `-inf` å±è”½æ— æ•ˆæ•°æ®ï¼Œæˆ–ä½¿ç”¨ Mask è®¡ç®— `sum(exp(x))` |
| **Loss è®¡ç®—å— Padding å½±å“** | å½’ä¸€åŒ–æ—¶ä»…é™¤ä»¥ **æœ‰æ•ˆæ•°æ®æ•°ç›®**ï¼Œå¿½ç•¥ Padding æ•°æ® |
| **é«˜æ•ˆè®¡ç®—ä¼˜åŒ–** | é‡‡ç”¨ SIMD å‘é‡åŒ–æˆ–ä½ç²¾åº¦è®¡ç®—ï¼ˆFP16 / CUDA `__half2`ï¼‰ |

é€šè¿‡è¿™äº›æ–¹æ³•ï¼Œå¯ä»¥é¿å… Padding æ•°æ®å¯¹ Softmaxã€Loss è®¡ç®—çš„å¹²æ‰°ï¼Œå¹¶æå‡è®¡ç®—æ•ˆç‡ã€‚


åœ¨å¹¶è¡Œè®¡ç®—ä¸­ï¼Œåˆ†æ”¯åˆ¤æ–­ï¼ˆå¦‚ `if-else`ï¼‰ä¼šå¯¼è‡´**çº¿ç¨‹åˆ†æ­§ï¼ˆThread Divergenceï¼‰** æˆ– **æŒ‡ä»¤æµæ°´çº¿åœæ»ï¼ˆPipeline Stallsï¼‰**ï¼Œå½±å“æ‰§è¡Œæ•ˆç‡ã€‚ä»¥ä¸‹æ˜¯ä¼˜åŒ–æ–¹æ¡ˆï¼š

---

## **1. é¿å…åˆ†æ”¯åˆ¤æ–­çš„æ–¹æ³•**
### **(1) ä½¿ç”¨æ©ç ï¼ˆMaskingï¼‰ä»£æ›¿åˆ†æ”¯**
#### **é—®é¢˜**
åœ¨ GPU æˆ– SIMD è®¡ç®—ä¸­ï¼Œ`if-else` å¯èƒ½å¯¼è‡´ä¸åŒçº¿ç¨‹æ‰§è¡Œä¸åŒæŒ‡ä»¤ï¼Œå¯¼è‡´ä¸²è¡ŒåŒ–æ‰§è¡Œï¼Œé™ä½ååé‡ã€‚

#### **ä¼˜åŒ–æ–¹æ³•**
ä½¿ç”¨ **æ©ç è¿ç®—**ï¼ˆMaskingï¼‰æ¥ä»£æ›¿ `if-else` åˆ¤æ–­ï¼š
- **CPU SIMD è®¡ç®—ï¼ˆAVXï¼‰**
  ```cpp
  #include <immintrin.h>  // AVX æŒ‡ä»¤

  void masked_softmax(float* x, float* mask, float* output, int size) {
      __m256 v_mask, v_x, v_exp, v_sum;
      v_sum = _mm256_setzero_ps();

      for (int i = 0; i < size; i += 8) {
          v_mask = _mm256_load_ps(mask + i);  // 0/1 mask
          v_x = _mm256_load_ps(x + i);
          v_exp = _mm256_exp_ps(v_x);
          v_exp = _mm256_mul_ps(v_exp, v_mask);  // ç›´æ¥å±è”½æ— æ•ˆæ•°æ®
          v_sum = _mm256_add_ps(v_sum, v_exp);
      }
  }
  ```
- **GPU CUDA è®¡ç®—**
  ```cuda
  __global__ void masked_softmax(float* x, float* mask, float* output, int size) {
      int idx = threadIdx.x + blockIdx.x * blockDim.x;
      if (idx < size) {
          float exp_x = exp(x[idx]);
          output[idx] = exp_x * mask[idx];  // ç›´æ¥å±è”½ Padding å½±å“
      }
  }
  ```

âœ… **ä¼˜åŠ¿**ï¼š
- é¿å… `if` åˆ¤æ–­ï¼Œæ‰€æœ‰çº¿ç¨‹æ‰§è¡Œç›¸åŒæŒ‡ä»¤ã€‚
- è®¡ç®—é‡å‡å°‘ï¼Œååé‡æå‡ã€‚

---

### **(2) ä½¿ç”¨é€‰æ‹©è¿ç®—ï¼ˆSelect Operationï¼‰ä»£æ›¿ `if-else`**
- **CPU**ï¼š`? :` é€‰æ‹©è¿ç®—
  ```cpp
  float masked_val = mask[i] ? exp(x[i]) : 0.0f;
  ```
- **GPUï¼ˆCUDAï¼‰**ï¼š
  ```cuda
  output[idx] = mask[idx] * exp(x[idx]);
  ```
- **SIMDï¼ˆAVXï¼‰**
  ```cpp
  v_exp = _mm256_blendv_ps(_mm256_setzero_ps(), v_exp, v_mask);
  ```

âœ… **ä¼˜åŠ¿**ï¼š
- ä¿è¯æ‰€æœ‰çº¿ç¨‹æ‰§è¡ŒåŒæ ·çš„æŒ‡ä»¤ï¼Œé¿å…åˆ†æ”¯é¢„æµ‹å¤±è´¥å¯¼è‡´çš„æµæ°´çº¿åœæ»ã€‚
- åœ¨ SIMD è®¡ç®—ä¸­ï¼Œé¿å…**å¯„å­˜å™¨åˆ‡æ¢å¼€é”€**ã€‚

---

## **2. å¹¶è¡Œå½’ä¸€åŒ–æ—¶é¿å… Padding å¹²æ‰°**
### **(1) ä½¿ç”¨ Warp çº§åˆ«å¹¶è¡ŒåŒ–å½’ä¸€åŒ–**
- **é—®é¢˜**ï¼šSoftmax è®¡ç®—ä¸­ï¼ŒPadding ä½ç½®çš„ `sum(exp(x))` å¯èƒ½ä¼šå½±å“å½’ä¸€åŒ–ã€‚
- **ä¼˜åŒ–**ï¼šé‡‡ç”¨ Warp çº§åˆ« **åˆ†å—å½’çº¦ï¼ˆBlock Reductionï¼‰**ï¼Œä»…åœ¨æœ‰æ•ˆæ•°æ®ä¸Šå½’ä¸€åŒ–ã€‚
- **CUDA Kernel ä»£ç **
  ```cuda
  __global__ void masked_softmax_warp(float* x, float* mask, float* output, int N) {
      __shared__ float sum_exp;
      int idx = threadIdx.x + blockIdx.x * blockDim.x;
      
      float val = (idx < N) ? exp(x[idx]) * mask[idx] : 0.0f;  // é¿å… if åˆ†æ”¯
      float sum = warpReduceSum(val);  // çº¿ç¨‹å½’çº¦æ±‚å’Œ

      __syncthreads();
      if (idx < N) {
          output[idx] = val / (sum + 1e-9);  // é¿å…é™¤é›¶é”™è¯¯
      }
  }
  ```
âœ… **ä¼˜åŠ¿**ï¼š
- çº¿ç¨‹é—´åŒæ­¥å‡å°‘ï¼Œæé«˜ååé‡ã€‚
- ä»…å¯¹æœ‰æ•ˆæ•°æ®è®¡ç®— Softmaxï¼Œé¿å…æ— æ•ˆæ•°æ®å½±å“ç»“æœã€‚

---

## **3. ä½¿ç”¨ç‰¹æ®ŠæŒ‡ä»¤ä¼˜åŒ–æ— æ•ˆæ•°æ®è¿‡æ»¤**
### **(1) x86 SIMDï¼šä½¿ç”¨ `_mm256_blendv_ps`**
- ç›´æ¥åœ¨ AVX è®¡ç®—ä¸­ç”¨ `blend` æŒ‡ä»¤å±è”½æ— æ•ˆæ•°æ®ï¼š
  ```cpp
  __m256 masked_x = _mm256_blendv_ps(_mm256_setzero_ps(), x, mask);
  ```

### **(2) ARM NEONï¼šä½¿ç”¨ `vbslq_f32`**
- åœ¨ ARM å¹³å°ï¼š
  ```cpp
  float32x4_t masked_x = vbslq_f32(mask, x, vdupq_n_f32(0.0f));
  ```

âœ… **ä¼˜åŠ¿**ï¼š
- é¿å…æ˜¾å¼ `if` è¯­å¥ï¼Œæé«˜æµæ°´çº¿æ‰§è¡Œæ•ˆç‡ã€‚

---

## **4. è®¡ç®— Loss æ—¶é¿å… Padding æ•°æ®å¹²æ‰°**
- **é—®é¢˜**ï¼šè®¡ç®— Loss æ—¶ï¼Œ`sum(loss) / N` å¯èƒ½ä¼šå—åˆ° Padding å½±å“ï¼Œå¯¼è‡´æ¢¯åº¦ä¼ æ’­é”™è¯¯ã€‚
- **ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š
  - ä»…å¯¹ **æœ‰æ•ˆæ•°æ®** è®¡ç®— Lossï¼Œä½¿ç”¨ **æœ‰æ•ˆæ•°æ®æ•°é‡å½’ä¸€åŒ–**ã€‚
  - **CUDA å®ç°**ï¼š
    ```cuda
    __global__ void masked_cross_entropy(float* pred, float* target, float* mask, float* loss, int N) {
        int idx = threadIdx.x + blockIdx.x * blockDim.x;
        if (idx < N) {
            float val = -target[idx] * log(pred[idx] + 1e-9);
            loss[idx] = val * mask[idx];  // åªè®¡ç®—æœ‰æ•ˆæ•°æ®
        }
    }
    ```
  - **SIMD å®ç°**ï¼š
    ```cpp
    __m256 v_loss = _mm256_mul_ps(v_target, _mm256_log_ps(_mm256_add_ps(v_pred, _mm256_set1_ps(1e-9))));
    v_loss = _mm256_mul_ps(v_loss, v_mask);
    ```

âœ… **ä¼˜åŠ¿**ï¼š
- **å¹¶è¡Œè®¡ç®—**é¿å… `if-else`ï¼Œæé«˜æµæ°´çº¿åˆ©ç”¨ç‡ã€‚
- **å±è”½æ— æ•ˆæ•°æ®**ï¼Œå‡å°‘ä¸å¿…è¦çš„è®¡ç®—ã€‚

---

## **5. æ€»ç»“**
| **ä¼˜åŒ–ç‚¹** | **ä¼˜åŒ–æ–¹æ³•** | **ä¼˜ç‚¹** |
|------------|-------------|---------|
| **Softmax è®¡ç®—** | ç”¨ `mask * exp(x)` ä»£æ›¿ `if-else` | é¿å…çº¿ç¨‹åˆ†æ­§ |
| **å½’ä¸€åŒ–è®¡ç®—** | é‡‡ç”¨ Warp çº§åˆ«å½’çº¦ | å‡å°‘åŒæ­¥å¼€é”€ |
| **Loss è®¡ç®—** | ä»…å¯¹æœ‰æ•ˆæ•°æ®è®¡ç®— Lossï¼Œè·³è¿‡ Padding | é¿å…æ¢¯åº¦é”™è¯¯ |
| **x86 SIMD ä¼˜åŒ–** | ä½¿ç”¨ `_mm256_blendv_ps` | é¿å… if è¯­å¥ |
| **ARM NEON ä¼˜åŒ–** | ä½¿ç”¨ `vbslq_f32` | é€‚é… ARM æ¶æ„ |

é€šè¿‡è¿™äº›æ–¹æ³•ï¼Œå¯ä»¥ **å®Œå…¨é¿å…** å¹¶è¡Œè®¡ç®—ä¸­çš„ `if-else`ï¼Œæé«˜ååé‡å’Œè®¡ç®—æ•ˆç‡ï¼ ğŸš€